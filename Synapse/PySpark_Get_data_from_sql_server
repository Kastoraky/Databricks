# Import the Python libraries
from pyspark.sql import *
import pandas as pd

# COMMAND ----------
#Create variables for the connection
jdbcHostname = "mypersonaldatabaseserver.database.windows.net"
jdbcDatabase = "Dictionary"
jdbcPort = 1433
jdbcUsername = "Kastoraky"
jdbcPassword = dbutils.secrets.get(scope="AzureSqlPassword", key="AzureSqlPassword")
jdbcUrl = "jdbc:sqlserver://{0}:{1};database={2};user={3};password={4}".format(jdbcHostname, jdbcPort, jdbcDatabase, jdbcUsername, jdbcPassword)

# COMMAND ----------
# Make the actual connection

jdbcUrl = "jdbc:sqlserver://{0}:{1};database={2}".format(jdbcHostname, jdbcPort, jdbcDatabase)
connectionProperties = {
  "user" : jdbcUsername,
  "password" : jdbcPassword,
  "driver" : "com.microsoft.sqlserver.jdbc.SQLServerDriver"
}
